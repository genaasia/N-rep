{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example of Packative Inference\n",
    "\n",
    "this should mirror the deployed API\n",
    "\n",
    "it requires:\n",
    "\n",
    "1. packative data spreadsheet (exported from google sheets)\n",
    "2. deployed weaviate, postgres with packative data pre-loaded\n",
    "3. envfile with postgress password, aws & azure openai credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, world!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from text2sql import hello\n",
    "print(hello.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/miniconda3/envs/text2sql/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from text2sql.data import PostgresDataset\n",
    "from text2sql.engine.embeddings import BedrockCohereEmbedder\n",
    "from text2sql.engine.retrieval import WeaviateRetriever\n",
    "from text2sql.engine.prompts import LegacyFewShotPromptFormatter\n",
    "from text2sql.engine.generation import AzureGenerator, BedrockGenerator\n",
    "from text2sql.engine.generation.postprocessing import extract_first_code_block\n",
    "from text2sql.evaluation.metrics import (\n",
    "    get_soft_f1_score,\n",
    "    get_intent_match,\n",
    "    get_sql_match,\n",
    "    get_execution_match\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create pipeline modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create \"dataset\" database reader\n",
    "packative_dataset = PostgresDataset(\n",
    "    \"localhost\",\n",
    "    5432,\n",
    "    \"genapostgre\",\n",
    "    os.getenv(\"POSTGRES_PASSWORD\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedder\n",
    "embedder = BedrockCohereEmbedder(\n",
    "    region_name=\"us-east-1\",\n",
    "    model=\"cohere.embed-multilingual-v3\",\n",
    "    input_type=\"clustering\",\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create retriever\n",
    "retriever = WeaviateRetriever(\n",
    "    host=\"localhost\", \n",
    "    port=8081, \n",
    "    grpc_port=50051, \n",
    "    collection_name=\"PackativeQueriesCohereClustering\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prompt formatter to generate few-shot learning prompts\n",
    "schema_description = packative_dataset.describe_database_schema(\"genapostgre\", mode=\"basic\")\n",
    "formatter = LegacyFewShotPromptFormatter(\n",
    "    database_type=\"postgres\",\n",
    "    few_shot_query_key=\"nl_ko_query\",\n",
    "    few_shot_target_key=\"sql_query\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 'gena-4o'\n"
     ]
    }
   ],
   "source": [
    "# create a LLM generator\n",
    "\n",
    "# model = \"meta.llama3-1-8b-instruct-v1:0\"\n",
    "# generator = BedrockGenerator(\n",
    "#     region_name=\"us-west-2\",\n",
    "#     model=model,\n",
    "#     post_func=extract_first_code_block,\n",
    "# )\n",
    "model = os.environ.get(\"AZURE_OPENAI_GEN_MODEL\")\n",
    "generator = AzureGenerator(\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_API_ENDPOINT\"),\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    model=model,\n",
    "    post_func=extract_first_code_block,\n",
    ")\n",
    "print(f\"using '{model}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into list of dicts\n",
    "packative_train_file = \"./data/packative_nl2sql_ko_train_revised_20241025.csv\"\n",
    "packative_test_file = \"./data/packative_nl2sql_eval_20241029(final).csv\"\n",
    "packative_train_data = pd.read_csv(packative_train_file).to_dict(orient=\"records\")\n",
    "packative_test_data = pd.read_csv(packative_test_file).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train embeddings from existing file './data/packative_query_cohere_embeddings.npy'\n"
     ]
    }
   ],
   "source": [
    "# embed queries and save embeddings to temp file \n",
    "packative_train_embeddings_file = \"./data/packative_query_cohere_embeddings.npy\"\n",
    "train_queries = [example[\"nl_ko_query\"] for example in packative_train_data]\n",
    "if not os.path.isfile(packative_train_embeddings_file):\n",
    "    print(f\"generating train embeddings and saving to '{packative_train_embeddings_file}'\")\n",
    "    train_embeddings = embedder.embed(train_queries, verbose=True)\n",
    "    np.save(packative_train_embeddings_file, train_embeddings)\n",
    "else:\n",
    "    print(f\"loading train embeddings from existing file '{packative_train_embeddings_file}'\")\n",
    "    train_embeddings = np.load(packative_train_embeddings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3702/3702 [00:00<00:00, 4456.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'collection_name': 'PackativeQueriesCohereClustering',\n",
       " 'properties': {'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "   'cleanupIntervalSeconds': 60,\n",
       "   'indexNullState': False,\n",
       "   'indexPropertyLength': False,\n",
       "   'indexTimestamps': False,\n",
       "   'stopwords': {'preset': 'en'}},\n",
       "  'multiTenancyConfig': {'enabled': False,\n",
       "   'autoTenantCreation': False,\n",
       "   'autoTenantActivation': False},\n",
       "  'properties': [{'name': 'no_sql_template',\n",
       "    'dataType': ['int'],\n",
       "    'indexFilterable': True,\n",
       "    'indexSearchable': False,\n",
       "    'indexRangeFilters': False,\n",
       "    'tokenization': None,\n",
       "    'moduleConfig': {'none': {}}},\n",
       "   {'name': 'sql_template_type',\n",
       "    'dataType': ['text'],\n",
       "    'indexFilterable': True,\n",
       "    'indexSearchable': True,\n",
       "    'indexRangeFilters': False,\n",
       "    'tokenization': 'word',\n",
       "    'moduleConfig': {'none': {}}},\n",
       "   {'name': 'sql_template',\n",
       "    'dataType': ['text'],\n",
       "    'indexFilterable': True,\n",
       "    'indexSearchable': True,\n",
       "    'indexRangeFilters': False,\n",
       "    'tokenization': 'word',\n",
       "    'moduleConfig': {'none': {}}},\n",
       "   {'name': 'sql_query',\n",
       "    'dataType': ['text'],\n",
       "    'indexFilterable': True,\n",
       "    'indexSearchable': True,\n",
       "    'indexRangeFilters': False,\n",
       "    'tokenization': 'word',\n",
       "    'moduleConfig': {'none': {}}},\n",
       "   {'name': 'nl_ko_query',\n",
       "    'dataType': ['text'],\n",
       "    'indexFilterable': True,\n",
       "    'indexSearchable': True,\n",
       "    'indexRangeFilters': False,\n",
       "    'tokenization': 'word',\n",
       "    'moduleConfig': {'none': {}}}],\n",
       "  'replicationConfig': {'factor': 1,\n",
       "   'asyncEnabled': False,\n",
       "   'deletionStrategy': 'NoAutomatedResolution'},\n",
       "  'shardingConfig': {'virtualPerPhysical': 128,\n",
       "   'desiredCount': 1,\n",
       "   'actualCount': 1,\n",
       "   'desiredVirtualCount': 128,\n",
       "   'actualVirtualCount': 128,\n",
       "   'key': '_id',\n",
       "   'strategy': 'hash',\n",
       "   'function': 'murmur3'},\n",
       "  'vectorIndexConfig': {'cleanupIntervalSeconds': 300,\n",
       "   'distanceMetric': 'cosine',\n",
       "   'dynamicEfMin': 100,\n",
       "   'dynamicEfMax': 500,\n",
       "   'dynamicEfFactor': 8,\n",
       "   'ef': -1,\n",
       "   'efConstruction': 128,\n",
       "   'filterStrategy': 'sweeping',\n",
       "   'flatSearchCutoff': 40000,\n",
       "   'maxConnections': 32,\n",
       "   'skip': False,\n",
       "   'vectorCacheMaxObjects': 1000000000000},\n",
       "  'vectorIndexType': 'hnsw',\n",
       "  'vectorizer': 'none',\n",
       "  'class': 'PackativeQueriesCohereClustering',\n",
       "  'moduleConfig': {}},\n",
       " 'count': 3656}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.populate_collection(\n",
    "    embeddings=train_embeddings,\n",
    "    data=packative_train_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WIP: predict\n",
    "\n",
    "todo: manage this with a class, and improve throughput with batched and/or threaded inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/146 [00:00<?, ?it/s]/home/derek/miniconda3/envs/text2sql/lib/python3.12/site-packages/botocore/auth.py:424: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  datetime_now = datetime.datetime.utcnow()\n",
      "100%|██████████| 146/146 [04:16<00:00,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "# inference all test samples through \"pipeline\"\n",
    "test_results = []\n",
    "for test_sample in tqdm.tqdm(packative_test_data):\n",
    "    sample_query = test_sample[\"nl_ko_query\"]\n",
    "    sample_sql = test_sample[\"sql_query\"]\n",
    "    # get similar queries\n",
    "    few_shot_examples = retriever.query(embedder.embed(sample_query), top_k=3)\n",
    "    # create chat messages\n",
    "    messages = formatter.generate_messages(\n",
    "    schema_description=schema_description,\n",
    "    query=sample_query,\n",
    "    few_shot_examples=few_shot_examples,\n",
    "    )\n",
    "    # inference\n",
    "    prediction: str | None = generator.generate(messages)\n",
    "    # validate\n",
    "    results: dict = packative_dataset.validate_query(\"genapostgre\", prediction)\n",
    "    # todo: repair & re-evaluate, when implemented\n",
    "    # save\n",
    "    output = test_sample.copy()\n",
    "    output[\"prediction\"] = prediction\n",
    "    output.update(results)\n",
    "    test_results.append(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WIP: Evaluate\n",
    "\n",
    "todo: manage this with a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target_sql = [row.get(\"sql_query\") for row in packative_test_data]\n",
    "test_target_executions = [json.loads(row.get(\"execution_result\")) for row in packative_test_data]\n",
    "test_predicted_sql = [row.get(\"prediction\") for row in test_results]\n",
    "test_predicted_executions = [row.get(\"execution_result\") for row in test_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One fix for LT09 not applied, it would re-cause the same error.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in formatting query: None. Returning original query.\n",
      "Error in formatting query: None. Returning original query.\n"
     ]
    }
   ],
   "source": [
    "sql_match_scores = [get_sql_match(test_predicted_sql[i], test_target_sql[i]) for i in range(len(test_predicted_executions))]\n",
    "execution_match_scores = [get_execution_match(test_predicted_executions[i], test_target_executions[i]) for i in range(len(test_predicted_executions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean sql  match: 0.3561643835616438\n",
      "mean exec match: 0.363013698630137\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean sql  match: {np.mean(sql_match_scores)}\")\n",
    "print(f\"mean exec match: {np.mean(execution_match_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are buggy, so 0.0 if fail\n",
    "soft_f1_scores = []\n",
    "intent_scores = []\n",
    "for i in range(len(test_predicted_executions)):\n",
    "    try:\n",
    "        soft_f1_scores.append(get_soft_f1_score(test_predicted_executions[i], test_target_executions[i]))\n",
    "    except:\n",
    "        soft_f1_scores.append(0.0)\n",
    "    try:\n",
    "        intent_scores.append(get_intent_match(test_predicted_executions[i], test_target_executions[i]))\n",
    "    except:\n",
    "        intent_scores.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean soft f1: 0.6104236706976434\n",
      "mean intent : 0.6027397260273972\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean soft f1: {np.mean(soft_f1_scores)}\")\n",
    "print(f\"mean intent : {np.mean(intent_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
