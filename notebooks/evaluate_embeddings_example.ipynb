{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example of evaluating embeddings on text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, world!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from text2sql import hello\n",
    "print(hello.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from text2sql.engine.embeddings import (\n",
    "    AzureEmbedder, \n",
    "    BedrockCohereEmbedder, \n",
    "    BedrockTitanv2Embedder, \n",
    "    SentenceTransformerEmbedder,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create embedders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_key: 3dc\n",
      "azure_endpoint: https://gena-gpt-2.openai.azure.com/\n",
      "api_version: 2024-06-01\n",
      "model: gena-text-embedding-3-small\n"
     ]
    }
   ],
   "source": [
    "api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_endpoint=os.environ.get(\"AZURE_OPENAI_API_ENDPOINT\")\n",
    "api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\")\n",
    "model=os.environ.get(\"AZURE_OPENAI_MODEL\")\n",
    "print(f\"api_key: {api_key[:3]}\")\n",
    "print(f\"azure_endpoint: {azure_endpoint}\")\n",
    "print(f\"api_version: {api_version}\")\n",
    "print(f\"model: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_ada_embedder = AzureEmbedder(\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_API_ENDPOINT\"),\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    model=\"gena-embedding\",\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_te3_embedder = AzureEmbedder(\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_API_ENDPOINT\"),\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    model=\"gena-text-embedding-3-small\",\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_cohere_clustering_embedder = BedrockCohereEmbedder(\n",
    "    region_name=\"us-east-1\",\n",
    "    model=\"cohere.embed-multilingual-v3\",\n",
    "    input_type=\"clustering\",\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_cohere_classification_embedder = BedrockCohereEmbedder(\n",
    "    region_name=\"us-east-1\",\n",
    "    model=\"cohere.embed-multilingual-v3\",\n",
    "    input_type=\"classification\",\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_cohere_document_embedder = BedrockCohereEmbedder(\n",
    "    region_name=\"us-east-1\",\n",
    "    model=\"cohere.embed-multilingual-v3\",\n",
    "    input_type=\"search_document\",\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_cohere_query_embedder = BedrockCohereEmbedder(\n",
    "    region_name=\"us-east-1\",\n",
    "    model=\"cohere.embed-multilingual-v3\",\n",
    "    input_type=\"search_query\",\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_titan_embedder = BedrockTitanv2Embedder(\n",
    "    region_name=\"us-east-1\",\n",
    "    model=\"amazon.titan-embed-text-v2:0\",\n",
    "    dimensions=1024,\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/miniconda3/envs/text2sql/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentence_transformer_embedder = SentenceTransformerEmbedder(\n",
    "    model_path=\"sentence-transformers/LaBSE\",\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset\n",
    "\n",
    "we're using BANKING77, available at: https://huggingface.co/datasets/mteb/banking77/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.4'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/data/gena_data/BANKING77\"\n",
    "train_file = os.path.join(data_path, \"train.jsonl\")\n",
    "test_file = os.path.join(data_path, \"test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            datum = line.strip(\"\\n\")\n",
    "            if len(datum) > 0:\n",
    "                data.append(json.loads(datum))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: 10003, test_data: 3080\n"
     ]
    }
   ],
   "source": [
    "train_data = load_jsonl(train_file)\n",
    "test_data = load_jsonl(test_file)\n",
    "print(f\"train_data: {len(train_data)}, test_data: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sampled_data: 1925\n"
     ]
    }
   ],
   "source": [
    "# subsample by first n examples for each label\n",
    "n = 25\n",
    "sorted_data = defaultdict(list)\n",
    "for datum in train_data:\n",
    "    label = datum[\"label\"]\n",
    "    sorted_data[label].append(datum)\n",
    "train_sampled_data = []\n",
    "for label, data in sorted_data.items():\n",
    "    train_sampled_data.extend(data[:n])\n",
    "print(f\"train_sampled_data: {len(train_sampled_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_sampled_data: 770\n"
     ]
    }
   ],
   "source": [
    "# subsample by first n examples for each label\n",
    "n = 10\n",
    "sorted_data = defaultdict(list)\n",
    "for datum in test_data:\n",
    "    label = datum[\"label\"]\n",
    "    sorted_data[label].append(datum)\n",
    "test_sampled_data = []\n",
    "for label, data in sorted_data.items():\n",
    "    test_sampled_data.extend(data[:n])\n",
    "print(f\"test_sampled_data: {len(test_sampled_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = [datum[\"text\"] for datum in train_sampled_data]\n",
    "train_labels = [datum[\"label\"] for datum in train_sampled_data]\n",
    "test_texts = [datum[\"text\"] for datum in test_sampled_data]\n",
    "test_labels = [datum[\"label\"] for datum in test_sampled_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_data_leaks: 0\n"
     ]
    }
   ],
   "source": [
    "check_data_leaks = set(train_texts).intersection(set(test_texts))\n",
    "print(f\"check_data_leaks: {len(check_data_leaks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embed all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding traindata with openai-ada-002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241/241 [01:15<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding traindata with openai-text-emb3-small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241/241 [02:10<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding traindata with cohere-multi-clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/241 [00:00<?, ?it/s]/home/derek/miniconda3/envs/text2sql/lib/python3.12/site-packages/botocore/auth.py:424: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  datetime_now = datetime.datetime.utcnow()\n",
      "100%|██████████| 241/241 [01:58<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding traindata with cohere-multi-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241/241 [01:22<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding traindata with cohere-multi-document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241/241 [04:02<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding traindata with sentence-transformer-labse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1925/1925 [00:46<00:00, 41.59it/s]\n"
     ]
    }
   ],
   "source": [
    "for emb_name, embedder in [\n",
    "        (\"openai-ada-002\", azure_ada_embedder), \n",
    "        (\"openai-text-emb3-small\", azure_te3_embedder), \n",
    "        (\"cohere-multi-clustering\", bedrock_cohere_clustering_embedder), \n",
    "        (\"cohere-multi-classification\", bedrock_cohere_classification_embedder), \n",
    "        (\"cohere-multi-document\", bedrock_cohere_document_embedder), \n",
    "        (\"sentence-transformer-labse\", sentence_transformer_embedder),\n",
    "    ]:\n",
    "    save_dir = os.path.join(data_path, \"train_embeddings\", emb_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    fname = f\"train-sampled-embeddings-{emb_name}.npy\"\n",
    "    if os.path.isfile(os.path.join(save_dir, fname)):\n",
    "        print(f\"embedding traindata with {emb_name} already exists\")\n",
    "        continue\n",
    "    print(f\"embedding traindata with {emb_name}\")\n",
    "    time.sleep(0.5)\n",
    "    train_embeddings = embedder.embed(train_texts, verbose=True)\n",
    "    np.save(os.path.join(save_dir, fname), train_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding test data with openai-ada-002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [02:02<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding test data with openai-text-emb3-small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:56<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding test data with cohere-multi-clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/97 [00:00<?, ?it/s]/home/derek/miniconda3/envs/text2sql/lib/python3.12/site-packages/botocore/auth.py:424: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  datetime_now = datetime.datetime.utcnow()\n",
      "100%|██████████| 97/97 [02:20<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding test data with cohere-multi-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [01:18<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding test data with cohere-multi-document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:33<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding test data with sentence-transformer-labse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:18<00:00, 41.77it/s]\n"
     ]
    }
   ],
   "source": [
    "for emb_name, embedder in [\n",
    "        (\"openai-ada-002\", azure_ada_embedder), \n",
    "        (\"openai-text-emb3-small\", azure_te3_embedder), \n",
    "        (\"cohere-multi-clustering\", bedrock_cohere_clustering_embedder), \n",
    "        (\"cohere-multi-classification\", bedrock_cohere_classification_embedder), \n",
    "        (\"cohere-multi-document\", bedrock_cohere_query_embedder),  # use query here \n",
    "        (\"sentence-transformer-labse\", sentence_transformer_embedder),\n",
    "    ]:\n",
    "    save_dir = os.path.join(data_path, \"test_embeddings\", emb_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    fname = f\"test-embeddings-{emb_name}.npy\"\n",
    "    if os.path.isfile(os.path.join(save_dir, fname)):\n",
    "        print(f\"embedding traindata with {emb_name} already exists\")\n",
    "        continue\n",
    "    print(f\"embedding test data with {emb_name}\")\n",
    "    time.sleep(0.5)\n",
    "    test_embeddings = embedder.embed(test_texts, verbose=True)\n",
    "    np.save(os.path.join(save_dir, fname), test_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking embeddings for openai-ada-002\n",
      "ok\n",
      "checking embeddings for openai-text-emb3-small\n",
      "ok\n",
      "checking embeddings for cohere-multi-clustering\n",
      "ok\n",
      "checking embeddings for cohere-multi-classification\n",
      "ok\n",
      "checking embeddings for cohere-multi-document\n",
      "ok\n",
      "checking embeddings for sentence-transformer-labse\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# validate embedding outputs\n",
    "for emb_name, _ in [\n",
    "        (\"openai-ada-002\", azure_ada_embedder), \n",
    "        (\"openai-text-emb3-small\", azure_te3_embedder), \n",
    "        (\"cohere-multi-clustering\", bedrock_cohere_clustering_embedder), \n",
    "        (\"cohere-multi-classification\", bedrock_cohere_classification_embedder), \n",
    "        (\"cohere-multi-document\", bedrock_cohere_document_embedder), \n",
    "        (\"sentence-transformer-labse\", sentence_transformer_embedder),\n",
    "    ]:\n",
    "    print(f\"checking embeddings for {emb_name}\")\n",
    "    train_fname = f\"train-sampled-embeddings-{emb_name}.npy\"\n",
    "    train_embedding_file = os.path.join(data_path, \"train_embeddings\", emb_name, train_fname)\n",
    "    train_embeddings = np.load(train_embedding_file)\n",
    "    if len(train_embeddings) != len(train_texts):\n",
    "        print(f\"train_embeddings: {train_embeddings.shape}, train_texts: {len(train_texts)}\")\n",
    "        continue\n",
    "    test_fname = f\"test-embeddings-{emb_name}.npy\"\n",
    "    test_embedding_file = os.path.join(data_path, \"test_embeddings\", emb_name, test_fname)\n",
    "    test_embeddings = np.load(test_embedding_file)\n",
    "    if len(test_embeddings) != len(test_texts):\n",
    "        print(f\"test_embeddings: {test_embeddings.shape}, train_texts: {len(test_texts)}\")\n",
    "        continue\n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from sklearn.preprocessing import normalize\n",
    "from text2sql.engine.retrieval import LocalRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'openai-ada-002' norm=True distance='cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:03<00:00, 193.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'openai-ada-002' norm=True distance='euclidean'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 485.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'openai-ada-002' norm=False distance='cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:03<00:00, 203.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'openai-ada-002' norm=False distance='euclidean'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 491.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'openai-text-emb3-small' norm=True distance='cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:03<00:00, 196.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'openai-text-emb3-small' norm=True distance='euclidean'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 489.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'openai-text-emb3-small' norm=False distance='cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:03<00:00, 203.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'openai-text-emb3-small' norm=False distance='euclidean'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 492.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'cohere-multi-clustering' norm=True distance='cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:03<00:00, 236.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'cohere-multi-clustering' norm=True distance='euclidean'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 733.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'cohere-multi-clustering' norm=False distance='cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:02<00:00, 290.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'cohere-multi-clustering' norm=False distance='euclidean'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 715.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'cohere-multi-classification' norm=True distance='cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:02<00:00, 295.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'cohere-multi-classification' norm=True distance='euclidean'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 716.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'cohere-multi-classification' norm=False distance='cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:02<00:00, 260.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'cohere-multi-classification' norm=False distance='euclidean'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 715.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'cohere-multi-document' norm=True distance='cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:02<00:00, 289.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'cohere-multi-document' norm=True distance='euclidean'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 716.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'cohere-multi-document' norm=False distance='cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:02<00:00, 295.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'cohere-multi-document' norm=False distance='euclidean'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 715.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'sentence-transformer-labse' norm=True distance='cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 757.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'sentence-transformer-labse' norm=True distance='euclidean'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 768.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'sentence-transformer-labse' norm=False distance='cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 754.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test 'sentence-transformer-labse' norm=False distance='euclidean'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 615.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# run tests\n",
    "result_dict = {}\n",
    "for emb_name, _ in [\n",
    "        (\"openai-ada-002\", azure_ada_embedder), \n",
    "        (\"openai-text-emb3-small\", azure_te3_embedder), \n",
    "        (\"cohere-multi-clustering\", bedrock_cohere_clustering_embedder), \n",
    "        (\"cohere-multi-classification\", bedrock_cohere_classification_embedder), \n",
    "        (\"cohere-multi-document\", bedrock_cohere_document_embedder), \n",
    "        (\"sentence-transformer-labse\", sentence_transformer_embedder),\n",
    "    ]:\n",
    "    for norm in (True, False):\n",
    "        for distance in (\"cosine\", \"euclidean\"):\n",
    "            test_name = f\"{emb_name}_norm:{norm}_distance:{distance}\"\n",
    "            print(f\"running test '{emb_name}' {norm=} {distance=}\")\n",
    "            time.sleep(0.5)\n",
    "            train_fname = f\"train-sampled-embeddings-{emb_name}.npy\"\n",
    "            train_embedding_file = os.path.join(data_path, \"train_embeddings\", emb_name, train_fname)\n",
    "            train_embeddings = np.load(train_embedding_file)\n",
    "            test_fname = f\"test-embeddings-{emb_name}.npy\"\n",
    "            test_embedding_file = os.path.join(data_path, \"test_embeddings\", emb_name, test_fname)\n",
    "            test_embeddings = np.load(test_embedding_file)\n",
    "            if norm:\n",
    "                test_fmt_embeddings = normalize(test_embeddings)\n",
    "            retriever = LocalRetriever(train_embeddings, train_sampled_data, norm=norm, distance_metric=distance)\n",
    "            top_labels = []\n",
    "            for i in tqdm.trange(len(test_texts)):\n",
    "                emb = test_fmt_embeddings[i]\n",
    "                results = retriever.query(emb, top_k=10)\n",
    "                top_label = [result[\"data\"][\"label\"] for result in results]\n",
    "                top_labels.append(top_label)\n",
    "            result_dict[test_name] = top_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = list(result_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai-ada-002_norm:True_distance:cosine: macro_precision=0.904423102150375, macro_recall=0.9000000000000004, micro_f1=0.9 macro_f1=0.898537292633263\n",
      "openai-ada-002_norm:True_distance:euclidean: macro_precision=0.904423102150375, macro_recall=0.9000000000000004, micro_f1=0.9 macro_f1=0.898537292633263\n",
      "openai-ada-002_norm:False_distance:cosine: macro_precision=0.904423102150375, macro_recall=0.9000000000000004, micro_f1=0.9 macro_f1=0.898537292633263\n",
      "openai-ada-002_norm:False_distance:euclidean: macro_precision=0.904423102150375, macro_recall=0.9000000000000004, micro_f1=0.9 macro_f1=0.898537292633263\n",
      "openai-text-emb3-small_norm:True_distance:cosine: macro_precision=0.8972104014311807, macro_recall=0.8922077922077922, micro_f1=0.8922077922077922 macro_f1=0.8904681082423449\n",
      "openai-text-emb3-small_norm:True_distance:euclidean: macro_precision=0.8972104014311807, macro_recall=0.8922077922077922, micro_f1=0.8922077922077922 macro_f1=0.8904681082423449\n",
      "openai-text-emb3-small_norm:False_distance:cosine: macro_precision=0.8972104014311807, macro_recall=0.8922077922077922, micro_f1=0.8922077922077922 macro_f1=0.8904681082423449\n",
      "openai-text-emb3-small_norm:False_distance:euclidean: macro_precision=0.8972104014311807, macro_recall=0.8922077922077922, micro_f1=0.8922077922077922 macro_f1=0.8904681082423449\n",
      "cohere-multi-clustering_norm:True_distance:cosine: macro_precision=0.8975590426889127, macro_recall=0.8922077922077922, micro_f1=0.8922077922077922 macro_f1=0.890856320212144\n",
      "cohere-multi-clustering_norm:True_distance:euclidean: macro_precision=0.8975590426889127, macro_recall=0.8922077922077922, micro_f1=0.8922077922077922 macro_f1=0.890856320212144\n",
      "cohere-multi-clustering_norm:False_distance:cosine: macro_precision=0.8975590426889127, macro_recall=0.8922077922077922, micro_f1=0.8922077922077922 macro_f1=0.890856320212144\n",
      "cohere-multi-clustering_norm:False_distance:euclidean: macro_precision=0.8975590426889127, macro_recall=0.8922077922077922, micro_f1=0.8922077922077922 macro_f1=0.890856320212144\n",
      "cohere-multi-classification_norm:True_distance:cosine: macro_precision=0.8975590426889127, macro_recall=0.8922077922077922, micro_f1=0.8922077922077922 macro_f1=0.890856320212144\n",
      "cohere-multi-classification_norm:True_distance:euclidean: macro_precision=0.8975590426889127, macro_recall=0.8922077922077922, micro_f1=0.8922077922077922 macro_f1=0.890856320212144\n",
      "cohere-multi-classification_norm:False_distance:cosine: macro_precision=0.8975590426889127, macro_recall=0.8922077922077922, micro_f1=0.8922077922077922 macro_f1=0.890856320212144\n",
      "cohere-multi-classification_norm:False_distance:euclidean: macro_precision=0.8975590426889127, macro_recall=0.8922077922077922, micro_f1=0.8922077922077922 macro_f1=0.890856320212144\n",
      "cohere-multi-document_norm:True_distance:cosine: macro_precision=0.9091110188512787, macro_recall=0.9012987012987014, micro_f1=0.9012987012987013 macro_f1=0.9009017563944465\n",
      "cohere-multi-document_norm:True_distance:euclidean: macro_precision=0.9091110188512787, macro_recall=0.9012987012987014, micro_f1=0.9012987012987013 macro_f1=0.9009017563944465\n",
      "cohere-multi-document_norm:False_distance:cosine: macro_precision=0.9091110188512787, macro_recall=0.9012987012987014, micro_f1=0.9012987012987013 macro_f1=0.9009017563944465\n",
      "cohere-multi-document_norm:False_distance:euclidean: macro_precision=0.9102916563955527, macro_recall=0.902597402597403, micro_f1=0.9025974025974026 macro_f1=0.902138614774162\n",
      "sentence-transformer-labse_norm:True_distance:cosine: macro_precision=0.7888890796835794, macro_recall=0.7675324675324675, micro_f1=0.7675324675324675 macro_f1=0.7664073993494323\n",
      "sentence-transformer-labse_norm:True_distance:euclidean: macro_precision=0.7888890796835794, macro_recall=0.7675324675324675, micro_f1=0.7675324675324675 macro_f1=0.7664073993494323\n",
      "sentence-transformer-labse_norm:False_distance:cosine: macro_precision=0.7888890796835794, macro_recall=0.7675324675324675, micro_f1=0.7675324675324675 macro_f1=0.7664073993494323\n",
      "sentence-transformer-labse_norm:False_distance:euclidean: macro_precision=0.7888890796835794, macro_recall=0.7675324675324675, micro_f1=0.7675324675324675 macro_f1=0.7664073993494323\n"
     ]
    }
   ],
   "source": [
    "results_dict = []\n",
    "for test_name in test_names:\n",
    "    top_labels = result_dict[test_name]\n",
    "    test_preds = [row[0] for row in top_labels]\n",
    "    macro_precision = precision_score(test_labels, test_preds, average=\"macro\")\n",
    "    macro_recall = recall_score(test_labels, test_preds, average=\"macro\")\n",
    "    micro_f1 = f1_score(test_labels, test_preds, average=\"micro\")\n",
    "    macro_f1 = f1_score(test_labels, test_preds, average=\"macro\")\n",
    "    print(f\"{test_name}: {macro_precision=}, {macro_recall=}, {micro_f1=} {macro_f1=}\")\n",
    "    test, norm_str, dist_str = test_name.split(\"_\")\n",
    "    norm_val = norm_str.split(\":\")[1]\n",
    "    dist_val = dist_str.split(\":\")[1]\n",
    "    results_dict.append({\"test_name\": test, \"norm\": norm_val, \"distance\": dist_val, \"macro_precision\": macro_precision, \"macro_recall\": macro_recall, \"micro_f1\": micro_f1, \"macro_f1\": macro_f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results_dict).to_csv(\"banking77_results.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
