{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example of Packative Inference\n",
    "\n",
    "this should mirror the deployed API\n",
    "\n",
    "it requires:\n",
    "\n",
    "1. packative data spreadsheet (exported from google sheets)\n",
    "2. deployed weaviate, postgres with packative data pre-loaded\n",
    "3. envfile with postgress password, aws & azure openai credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, world!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from text2sql import hello\n",
    "print(hello.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create postgres dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text2sql.data import PostgresDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "packative_dataset = PostgresDataset(\n",
    "    \"localhost\",\n",
    "    5432,\n",
    "    \"genapostgre\",\n",
    "    os.getenv(\"POSTGRES_PASSWORD\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'count': 10}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run a query on the database to test\n",
    "packative_dataset.query_database(\"genapostgre\", \"SELECT COUNT(DISTINCT bank) FROM bank_account;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load csv data from spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "packative_train_file = \"./data/packative_nl2sql_ko_train_revised_20241025.csv\"\n",
    "packative_test_file = \"./data/packative_nl2sql_eval_20241029(final).csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into list of dicts\n",
    "packative_train_data = pd.read_csv(packative_train_file).to_dict(orient=\"records\")\n",
    "packative_test_data = pd.read_csv(packative_test_file).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no_sql_template': 1,\n",
       " 'sql_template_type': 'sql_syntax',\n",
       " 'sql_template': 'SELECT * FROM {table1} FULL OUTER JOIN {table2} ON {table1}.{column3:uuid} = {table2}.{column4:uuid};',\n",
       " 'sql_query': 'SELECT * FROM customer FULL OUTER JOIN address ON customer.id = address.customer_id;',\n",
       " 'nl_ko_query': '고객 테이블과 주소 테이블을 조인하여 모든 세부 정보를 제공해 주세요.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packative_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no_sql_template': 1,\n",
       " 'sql_template_type': 'sql_syntax',\n",
       " 'sql_query': \"SELECT custom_field.field_name, custom_field.field_type, custom_field_value.value FROM custom_field INNER JOIN custom_field_value ON custom_field.id = custom_field_value.custom_field_id WHERE field_name like '%email%';\",\n",
       " 'nl_ko_query': \"사용자 정의 필드 이름에 'email'이 들어가는 필드 이름과 필드 타입, 필드 값을 보여주세요\",\n",
       " 'nl_en_query': \"Please show the field names, types, and values for custom fields that contain 'email' in their name.\",\n",
       " 'execution_result': '[{\"field_name\": \"email_53\", \"field_type\": \"string\", \"value\": \"Value 2\"}, {\"field_name\": \"email_83\", \"field_type\": \"string\", \"value\": \"Value 10\"}, {\"field_name\": \"email_3\", \"field_type\": \"string\", \"value\": \"Value 4_4\"}, {\"field_name\": \"email_63\", \"field_type\": \"string\", \"value\": \"Value 10_10\"}, {\"field_name\": \"email_13\", \"field_type\": \"string\", \"value\": \"Value 1_21\"}, {\"field_name\": \"email\", \"field_type\": \"string\", \"value\": \"Value 6_26\"}, {\"field_name\": \"email_73\", \"field_type\": \"string\", \"value\": \"Value 7_47\"}, {\"field_name\": \"email_33\", \"field_type\": \"string\", \"value\": \"Value 9_49\"}, {\"field_name\": \"email_23\", \"field_type\": \"string\", \"value\": \"Value 8_58\"}, {\"field_name\": \"email_43\", \"field_type\": \"string\", \"value\": \"Value 2_62\"}]'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packative_test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embed the training data for retrieval\n",
    "\n",
    "API v2 is using bedrock cohere \"multilingual v3\" in \"clustering\" mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/miniconda3/envs/text2sql/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from text2sql.engine.embeddings import BedrockCohereEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedder\n",
    "embedder = BedrockCohereEmbedder(\n",
    "    region_name=\"us-east-1\",\n",
    "    model=\"cohere.embed-multilingual-v3\",\n",
    "    input_type=\"clustering\",\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating train embeddings and saving to './data/packative_query_cohere_embeddings.npy'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/463 [00:00<?, ?it/s]/home/derek/miniconda3/envs/text2sql/lib/python3.12/site-packages/botocore/auth.py:424: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  datetime_now = datetime.datetime.utcnow()\n",
      "100%|██████████| 463/463 [03:40<00:00,  2.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# embed queries and save embeddings to temp file \n",
    "packative_train_embeddings_file = \"./data/packative_query_cohere_embeddings.npy\"\n",
    "train_queries = [example[\"nl_ko_query\"] for example in packative_train_data]\n",
    "if not os.path.isfile(packative_train_embeddings_file):\n",
    "    print(f\"generating train embeddings and saving to '{packative_train_embeddings_file}'\")\n",
    "    train_embeddings = embedder.embed(train_queries, verbose=True)\n",
    "    np.save(packative_train_embeddings_file, train_embeddings)\n",
    "else:\n",
    "    print(f\"loading train embeddings from existing file '{packative_train_embeddings_file}'\")\n",
    "    train_embeddings = np.load(packative_train_embeddings_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create local retriever\n",
    "\n",
    "we can use weaviate as well, but for ease of setup, use local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text2sql.engine.retrieval import WeaviateRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = WeaviateRetriever(\n",
    "    host=\"localhost\", \n",
    "    port=8081, \n",
    "    grpc_port=50051, \n",
    "    collection_name=\"PackativeQueriesCohereClustering\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3702/3702 [00:00<00:00, 5142.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'collection_name': 'PackativeQueriesCohereClustering',\n",
       " 'properties': {'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "   'cleanupIntervalSeconds': 60,\n",
       "   'indexNullState': False,\n",
       "   'indexPropertyLength': False,\n",
       "   'indexTimestamps': False,\n",
       "   'stopwords': {'preset': 'en'}},\n",
       "  'multiTenancyConfig': {'enabled': False,\n",
       "   'autoTenantCreation': False,\n",
       "   'autoTenantActivation': False},\n",
       "  'properties': [{'name': 'no_sql_template',\n",
       "    'dataType': ['int'],\n",
       "    'indexFilterable': True,\n",
       "    'indexSearchable': False,\n",
       "    'indexRangeFilters': False,\n",
       "    'tokenization': None,\n",
       "    'moduleConfig': {'none': {}}},\n",
       "   {'name': 'sql_template_type',\n",
       "    'dataType': ['text'],\n",
       "    'indexFilterable': True,\n",
       "    'indexSearchable': True,\n",
       "    'indexRangeFilters': False,\n",
       "    'tokenization': 'word',\n",
       "    'moduleConfig': {'none': {}}},\n",
       "   {'name': 'sql_template',\n",
       "    'dataType': ['text'],\n",
       "    'indexFilterable': True,\n",
       "    'indexSearchable': True,\n",
       "    'indexRangeFilters': False,\n",
       "    'tokenization': 'word',\n",
       "    'moduleConfig': {'none': {}}},\n",
       "   {'name': 'sql_query',\n",
       "    'dataType': ['text'],\n",
       "    'indexFilterable': True,\n",
       "    'indexSearchable': True,\n",
       "    'indexRangeFilters': False,\n",
       "    'tokenization': 'word',\n",
       "    'moduleConfig': {'none': {}}},\n",
       "   {'name': 'nl_ko_query',\n",
       "    'dataType': ['text'],\n",
       "    'indexFilterable': True,\n",
       "    'indexSearchable': True,\n",
       "    'indexRangeFilters': False,\n",
       "    'tokenization': 'word',\n",
       "    'moduleConfig': {'none': {}}}],\n",
       "  'replicationConfig': {'factor': 1,\n",
       "   'asyncEnabled': False,\n",
       "   'deletionStrategy': 'NoAutomatedResolution'},\n",
       "  'shardingConfig': {'virtualPerPhysical': 128,\n",
       "   'desiredCount': 1,\n",
       "   'actualCount': 1,\n",
       "   'desiredVirtualCount': 128,\n",
       "   'actualVirtualCount': 128,\n",
       "   'key': '_id',\n",
       "   'strategy': 'hash',\n",
       "   'function': 'murmur3'},\n",
       "  'vectorIndexConfig': {'cleanupIntervalSeconds': 300,\n",
       "   'distanceMetric': 'cosine',\n",
       "   'dynamicEfMin': 100,\n",
       "   'dynamicEfMax': 500,\n",
       "   'dynamicEfFactor': 8,\n",
       "   'ef': -1,\n",
       "   'efConstruction': 128,\n",
       "   'filterStrategy': 'sweeping',\n",
       "   'flatSearchCutoff': 40000,\n",
       "   'maxConnections': 32,\n",
       "   'skip': False,\n",
       "   'vectorCacheMaxObjects': 1000000000000},\n",
       "  'vectorIndexType': 'hnsw',\n",
       "  'vectorizer': 'none',\n",
       "  'class': 'PackativeQueriesCohereClustering',\n",
       "  'moduleConfig': {}},\n",
       " 'count': 3656}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.populate_collection(\n",
    "    embeddings=train_embeddings,\n",
    "    data=packative_train_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": \"58277bd0-f83a-572a-81d8-367a58785015\",\n",
      "    \"distance\": 3.737211227416992e-05,\n",
      "    \"data\": {\n",
      "      \"sql_template_type\": \"sql_syntax\",\n",
      "      \"sql_template\": \"SELECT * FROM {table1} FULL OUTER JOIN {table2} ON {table1}.{column3:uuid} = {table2}.{column4:uuid};\",\n",
      "      \"nl_ko_query\": \"\\uace0\\uac1d \\ud14c\\uc774\\ube14\\uacfc \\uc8fc\\uc18c \\ud14c\\uc774\\ube14\\uc744 \\uc870\\uc778\\ud558\\uc5ec \\ubaa8\\ub4e0 \\uc138\\ubd80 \\uc815\\ubcf4\\ub97c \\uc81c\\uacf5\\ud574 \\uc8fc\\uc138\\uc694.\",\n",
      "      \"sql_query\": \"SELECT * FROM customer FULL OUTER JOIN address ON customer.id = address.customer_id;\",\n",
      "      \"no_sql_template\": 1\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"32af7e18-fdfd-5e1e-a760-e22260bf1e02\",\n",
      "    \"distance\": 0.18406933546066284,\n",
      "    \"data\": {\n",
      "      \"no_sql_template\": 1,\n",
      "      \"sql_template_type\": \"sql_syntax\",\n",
      "      \"nl_ko_query\": \"\\uc8fc\\ubb38 \\ud14c\\uc774\\ube14\\uacfc \\uacb0\\uc81c \\ud14c\\uc774\\ube14\\uc744 \\uc870\\uc778\\ud558\\uc5ec \\ubaa8\\ub4e0 \\uc815\\ubcf4\\ub97c \\ubcf4\\uc5ec\\uc8fc\\uc138\\uc694.\",\n",
      "      \"sql_query\": \"SELECT * FROM \\\"order\\\" FULL OUTER JOIN payment ON \\\"order\\\".id = payment.order_id;\",\n",
      "      \"sql_template\": \"SELECT * FROM {table1} FULL OUTER JOIN {table2} ON {table1}.{column3:uuid} = {table2}.{column4:uuid};\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"9a01795d-54b5-5712-8f32-216769e3203c\",\n",
      "    \"distance\": 0.2021026611328125,\n",
      "    \"data\": {\n",
      "      \"sql_template_type\": \"sql_syntax\",\n",
      "      \"sql_template\": \"SELECT * FROM {table1} FULL OUTER JOIN {table2} ON {table1}.{column3:uuid} = {table2}.{column4:uuid};\",\n",
      "      \"nl_ko_query\": \"\\uace0\\uac1d \\ub370\\uc774\\ud130\\uc640 \\uc8fc\\uc18c \\ub370\\uc774\\ud130\\ub97c \\ud1b5\\ud569\\ud558\\uc5ec \\uc0b4\\ud3b4\\ubcf4\\uace0\\uc790 \\ud569\\ub2c8\\ub2e4.\",\n",
      "      \"sql_query\": \"SELECT * FROM customer FULL OUTER JOIN address ON customer.id = address.customer_id;\",\n",
      "      \"no_sql_template\": 1\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# search an (existing) query as a sanity test; top result should be the query itself\n",
    "search_query = packative_train_data[0][\"nl_ko_query\"]\n",
    "search_results = retriever.query(embedder.embed(search_query), top_k=3)\n",
    "print(json.dumps(search_results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database schema, prompt formatter\n",
    "\n",
    "by default, the API uses \"basic\" formatting in DAIL-SQL type format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text2sql.engine.prompts import LegacyFewShotPromptFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table 'email' with columns: id , created_at , updated_at , deleted_at , metadata , to , cc , bcc , subject , language , body , is_opened , first_opened_at , last_opened_at , entity_type , entity_id , tenant_id , creator_id , modifier_id\n",
      "table 'api_key' with columns: id , created_at , updated_at , deleted_at , name , value , tenant_id , user_id , metadata\n",
      "table 'business_registration' with columns: id , created_at , updated_at , deleted_at , registration_number , company_name , representative_name , date_of_issuance , date_of_commencement , business_type , business_item , email , address , tenant_id , document_id , business_registration_type , metadata\n",
      "table 'design_comment_thread' with columns: id , created_at , updated_at , deleted_at , page , tenant_id , order_item_design_id , user_id , customer_id , position_x , position_y , metadata\n",
      "table 'customer' with columns: id , created_at , updated_at , deleted_at , number , name , website , company_size , industry , reference , converted_da\n"
     ]
    }
   ],
   "source": [
    "# get formatted database schema description from the dataset\n",
    "schema_description = packative_dataset.describe_database_schema(\"genapostgre\", mode=\"basic\")\n",
    "print(schema_description[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prompt formatter to generate few-shot learning prompts\n",
    "formatter = LegacyFewShotPromptFormatter(\n",
    "    database_type=\"postgres\",\n",
    "    few_shot_query_key=\"nl_ko_query\",\n",
    "    few_shot_target_key=\"sql_query\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = formatter.generate_messages(\n",
    "    schema_description=schema_description,\n",
    "    query=\"how much wood could a woodchuck chuck if a woodchuck could chuck wood?\",\n",
    "    few_shot_examples=search_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json.dumps(messages, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM inference\n",
    "\n",
    "the `LegacyFewShotPromptFormatter` automatically requests that the output is in a markdown code block.\n",
    "\n",
    "so, we can pass the postprocessing function `extract_first_code_block` as `post_func` to remove the code block parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text2sql.engine.generation import AzureGenerator, BedrockGenerator\n",
    "from text2sql.engine.generation.postprocessing import extract_first_code_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"meta.llama3-1-8b-instruct-v1:0\"\n",
    "# generator = BedrockGenerator(\n",
    "#     region_name=\"us-west-2\",\n",
    "#     model=model,\n",
    "#     post_func=extract_first_code_block,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 'gena-4o'\n"
     ]
    }
   ],
   "source": [
    "model = os.environ.get(\"AZURE_OPENAI_GEN_MODEL\")\n",
    "generator = AzureGenerator(\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_API_ENDPOINT\"),\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    model=model,\n",
    "    post_func=extract_first_code_block,\n",
    ")\n",
    "\n",
    "print(f\"using '{model}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test inference on a training sample\n",
    "\n",
    "first, load the sample, then do retrieval and generation.\n",
    "\n",
    "then, try running the query on the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고객 테이블과 주소 테이블을 조인하여 모든 세부 정보를 제공해 주세요.\n",
      "SELECT * FROM customer FULL OUTER JOIN address ON customer.id = address.customer_id;\n"
     ]
    }
   ],
   "source": [
    "# load one training sample\n",
    "training_sample = packative_train_data[0]\n",
    "sample_query = training_sample[\"nl_ko_query\"]\n",
    "sample_sql = training_sample[\"sql_query\"]\n",
    "print(sample_query)\n",
    "print(sample_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today's date: Tuesday, November 12, 2024\n",
      "text query: 고객 테이블과 주소 테이블을 조인하여 모든 세부 정보를 제공해 주세요.\n",
      "please give me a postgres SQL query as markdown code block.\n"
     ]
    }
   ],
   "source": [
    "# create chat messages for LLM input\n",
    "few_shot_examples = retriever.query(embedder.embed(sample_query), top_k=4)[1:]  # it's training so remove the real query\n",
    "\n",
    "# create chat messages\n",
    "messages = formatter.generate_messages(\n",
    "    schema_description=schema_description,\n",
    "    query=sample_query,\n",
    "    few_shot_examples=search_results,\n",
    ")\n",
    "\n",
    "# this is the final user prompt\n",
    "print(messages[-1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:\n",
      "SELECT * FROM customer FULL OUTER JOIN address ON customer.id = address.customer_id;\n",
      "\n",
      "\n",
      "prediction:\n",
      "SELECT * FROM customer JOIN address ON customer.id = address.customer_id;\n"
     ]
    }
   ],
   "source": [
    "# do LLM inference\n",
    "prediction = generator.generate(messages)  # need better cleaning later\n",
    "print(f\"target:\\n{sample_sql}\\n\\n\")\n",
    "print(f\"prediction:\\n{prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated: True\n",
      "message: ok\n",
      "first execution result:\n",
      "{'id': UUID('ef02ee58-44d9-4a8c-a125-dfd1b511f8a1'), 'created_at': datetime.datetime(2023, 10, 10, 12, 3), 'updated_at': datetime.datetime(2023, 10, 10, 12, 3), 'deleted_at': None, 'number': '4', 'name': 'Riverside Bungalow', 'website': 'www.globalfinance.com_73', 'company_size': 'Large', 'industry': 'Finance', 'reference': None, 'converted_date': datetime.datetime(2023, 9, 25, 10, 45), 'secret_key': 'sk-54321_73', 'tenant_id': UUID('0063f7f8-eeac-4014-905f-d8086a588762'), 'creator_id': UUID('d2c3aefd-478e-4809-8afa-19a4f957e130'), 'modifier_id': UUID('d2c3aefd-478e-4809-8afa-19a4f957e130'), 'assignee_id': UUID('d2c3aefd-478e-4809-8afa-19a4f957e130'), 'business_registration_id': UUID('c63e5259-0f9e-48e8-8633-144ab84312da'), 'converted_from_id': UUID('bfb76548-5b32-43d9-a6a2-3c0d86669387'), 'type': 'Partner', 'metadata': {}, 'line1': '321 Bayou St', 'line2': None, 'city': 'Houston', 'state': 'TX', 'zip_code': '77001', 'primary': False, 'lead_id': UUID('0198888d-2273-40b9-a87a-058aaa72fb54'), 'customer_id': UUID('05014b81-4412-4fd2-80f9-7230a7125aeb')}\n"
     ]
    }
   ],
   "source": [
    "results = packative_dataset.validate_query(\"genapostgre\", prediction)\n",
    "print(f\"validated: {results.get('validated', False)}\")\n",
    "print(f\"message: {results.get('message', 'none')}\")\n",
    "print(f\"first execution result:\")\n",
    "print(results.get(\"execution_result\", [\"none\"])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP: predict (dev set example)\n",
    "\n",
    "todo: make some sort of `Experiment` or `Runner` class to do this\n",
    "\n",
    "todo: improve throughput with batched and/or threaded inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [04:02<00:00,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "# inference all test samples\n",
    "import tqdm\n",
    "test_results = []\n",
    "for test_sample in tqdm.tqdm(packative_test_data):\n",
    "    sample_query = test_sample[\"nl_ko_query\"]\n",
    "    sample_sql = test_sample[\"sql_query\"]\n",
    "    # get similar queries\n",
    "    few_shot_examples = retriever.query(embedder.embed(sample_query), top_k=3)\n",
    "    # create chat messages\n",
    "    messages = formatter.generate_messages(\n",
    "    schema_description=schema_description,\n",
    "    query=sample_query,\n",
    "    few_shot_examples=few_shot_examples,\n",
    "    )\n",
    "    # inference\n",
    "    prediction: str | None = generator.generate(messages)\n",
    "    # validate\n",
    "    results: dict = packative_dataset.validate_query(\"genapostgre\", prediction)\n",
    "    # todo: repair & re-evaluate, when implemented\n",
    "    # save\n",
    "    output = test_sample.copy()\n",
    "    output[\"prediction\"] = prediction\n",
    "    output.update(results)\n",
    "    test_results.append(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP: Evaluation\n",
    "\n",
    "wrap in some sort of `Evaluator` class to do this, or call from `Experiment` (above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text2sql.evaluation.metrics import (\n",
    "    get_soft_f1_score,\n",
    "    get_intent_match,\n",
    "    get_sql_match,\n",
    "    get_execution_match\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target_sql = [row.get(\"sql_query\") for row in packative_test_data]\n",
    "test_target_executions = [json.loads(row.get(\"execution_result\")) for row in packative_test_data]\n",
    "test_predicted_sql = [row.get(\"prediction\") for row in test_results]\n",
    "test_predicted_executions = [row.get(\"execution_result\") for row in test_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One fix for LT09 not applied, it would re-cause the same error.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in formatting query: None. Returning original query.\n",
      "Error in formatting query: None. Returning original query.\n",
      "Error in formatting query: None. Returning original query.\n"
     ]
    }
   ],
   "source": [
    "sql_match_scores = [get_sql_match(test_predicted_sql[i], test_target_sql[i]) for i in range(len(test_predicted_executions))]\n",
    "execution_match_scores = [get_execution_match(test_predicted_executions[i], test_target_executions[i]) for i in range(len(test_predicted_executions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean sql  match: 0.363013698630137\n",
      "mean exec match: 0.3356164383561644\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean sql  match: {np.mean(sql_match_scores)}\")\n",
    "print(f\"mean exec match: {np.mean(execution_match_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are buggy, so 0.0 if fail\n",
    "soft_f1_scores = []\n",
    "intent_scores = []\n",
    "for i in range(len(test_predicted_executions)):\n",
    "    try:\n",
    "        soft_f1_scores.append(get_soft_f1_score(test_predicted_executions[i], test_target_executions[i]))\n",
    "    except:\n",
    "        soft_f1_scores.append(0.0)\n",
    "    try:\n",
    "        intent_scores.append(get_intent_match(test_predicted_executions[i], test_target_executions[i]))\n",
    "    except:\n",
    "        intent_scores.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean soft f1: 0.5657182999648754\n",
      "mean intent : 0.5753424657534246\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean soft f1: {np.mean(soft_f1_scores)}\")\n",
    "print(f\"mean intent : {np.mean(intent_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
