{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import numpy as np\n",
    "import weaviate\n",
    "\n",
    "from sklearn.metrics.pairwise import distance_metrics, pairwise_distances\n",
    "\n",
    "from text2sql.engine.embeddings import SentenceTransformerEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/miniconda3/envs/text2sql/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentence_transformer_embedder = SentenceTransformerEmbedder(\n",
    "    model_path=\"sentence-transformers/LaBSE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with text from aeneid (public domain) \n",
    "# https://classics.mit.edu/Virgil/aeneid.1.i.html\n",
    "import os\n",
    "\n",
    "with open(\"aeneid_sample.txt\") as f:\n",
    "    texts = f.read().split(\"\\n\")\n",
    "texts = [t.strip().lstrip() for t in texts if t]\n",
    "\n",
    "if not os.path.exists(\"aeneid_sample_embeddings.npy\"):\n",
    "    embeddings = sentence_transformer_embedder.embed(texts, verbose=True)\n",
    "    np.save(\"aeneid_sample_embeddings.npy\", embeddings)\n",
    "else:\n",
    "    embeddings = np.load(\"aeneid_sample_embeddings.npy\")\n",
    "assert len(embeddings) == len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRetriever(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def query():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalRetriever(BaseRetriever):\n",
    "    \n",
    "    def __init__(self, embeddings: list[list[float]] | np.ndarray, data: list[dict], distance_metric: str = \"cosine\"):\n",
    "        if len(embeddings) != len(data):\n",
    "            raise ValueError(\"The number of embeddings must equal the number of data!\")\n",
    "        if distance_metric not in distance_metrics():\n",
    "            raise ValueError(f\"Unknown distance metric '{distance_metric}', must be one of {list(distance_metrics().keys())}\")\n",
    "        self.distance_metric = distance_metric\n",
    "        self.embeddings = np.array(embeddings)\n",
    "        self.data = data\n",
    "\n",
    "    def query(self, query_vector: list[float] | np.ndarray, top_k: int = 10) -> list[dict]:\n",
    "        query_vector = np.array(query_vector).reshape(1, -1)\n",
    "        distances = pairwise_distances(query_vector, self.embeddings, metric=self.distance_metric)[0]\n",
    "        indices = np.argsort(distances)\n",
    "        results = [{\"distance\": float(distances[i]), \"data\": self.data[i]} for i in indices[:top_k]]\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"line\": line + 1, \"text\": text} for line, text in enumerate(texts)]\n",
    "aeneid_retriever = LocalRetriever(embeddings=embeddings, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"Before his eyes his goddess mother stood:\"\n",
    "\n",
    "query_vector = sentence_transformer_embedder.embed(query_text)\n",
    "responses = aeneid_retriever.query(query_vector, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"distance\": 0.0,\n",
      "  \"data\": {\n",
      "    \"line\": 434,\n",
      "    \"text\": \"Before his eyes his goddess mother stood:\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"distance\": 0.38323378562927246,\n",
      "  \"data\": {\n",
      "    \"line\": 826,\n",
      "    \"text\": \"His mother goddess, with her hands divine,\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"distance\": 0.48103129863739014,\n",
      "  \"data\": {\n",
      "    \"line\": 487,\n",
      "    \"text\": \"Of her unhappy lord: the specter stares,\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"distance\": 0.49619847536087036,\n",
      "  \"data\": {\n",
      "    \"line\": 967,\n",
      "    \"text\": \"He walks Iulus in his mother's sight,\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"distance\": 0.4964240789413452,\n",
      "  \"data\": {\n",
      "    \"line\": 919,\n",
      "    \"text\": \"Her mother Leda's present, when she came\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for d in responses:\n",
    "    print(json.dumps(d, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
